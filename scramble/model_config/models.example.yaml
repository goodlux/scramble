# Example Model Configurations
#
# This file shows example configurations for different types of models
# Copy and modify these examples to create your models.yaml

# Anthropic Models
claude3_example:
  provider: anthropic
  model_id: claude-3-opus-20240229
  description: Example Claude 3 configuration
  parameters:
    temperature: 0.7
    max_tokens: 4096
    top_p: 0.9

# Ollama Models
ollama_example:
  provider: ollama
  model_id: phi4  # or llama2, mixtral, etc.
  description: Example Ollama model configuration
  parameters:
    # Core parameters (commonly used)
    temperature: 0.7       # Randomness (0-1)
    max_tokens: 2048      # Maximum response length
    top_p: 0.9           # Nucleus sampling threshold
    top_k: 40            # Limit vocabulary to top K options
    num_ctx: 4096        # Context window size

    # Optional parameters (model-specific)
    stop: ["\n\n", "Human:", "Assistant:"]  # Custom stop sequences
    
    # Advanced parameters (override provider defaults if needed)
    # num_gpu: 1         # Number of GPUs (provider default)
    # num_thread: 8      # CPU threads (provider default)
    # seed: 42           # Set seed for reproducibility
    # repeat_penalty: 1.1 # Custom repetition penalty