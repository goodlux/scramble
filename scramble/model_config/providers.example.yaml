# Example configuration files for many LiteLLM providers.
# You can copy this to your providers.yaml file. If a provider isn't in this list,
# you can create a new one in your providers.yaml file. The {model_id} will be filled
# with whatever you put in the model_id field in your models.yaml file.
#
# Of special note:
#
# Google uses gemini, where most providers use their name: gemini/{model_id}
# OpenAi does not use anything before the model_id: {model_id}
#
# Both of these should work copied as is

anthropic:
  format: anthropic/{model_id}
  api_key: default_anthropic_key_replace_me
  description: Anthropic's Claude models

ollama:
  format: {model_id}
  api_key: not_needed  # Ollama doesn't require API key for local models
  base_url: http://localhost:11434
  description: Local models running via Ollama
  # Provider-level options for all Ollama models
  provider_options:
    # Hardware utilization
    num_gpu: 1              # Number of GPUs to use (0 for CPU only)
    num_thread: 8           # Number of CPU threads for computation

    # Advanced sampling parameters
    mirostat: 0            # Mirostat sampling version (0 = disabled, 1 = v1, 2 = v2)
    mirostat_eta: 0.1      # Mirostat learning rate (default: 0.1)
    mirostat_tau: 5.0      # Mirostat target entropy (default: 5.0)

    # Token generation controls
    repeat_last_n: 64      # Number of tokens to look back for repetition
    repeat_penalty: 1.1    # Penalty for repetition (1.0 = disabled, >1.0 = stronger)
    tfs_z: 1              # Tail free sampling, higher = more focused (1.0 = disabled)
    
    # Reproducibility
    seed: 42              # RNG seed (0 for random)

# Other provider examples
anthropic-aws:
  format: anthropic-aws/{model_id}
  api_key: default_anthropic_aws_key_replace_me
  description: Anthropic models on AWS

azure:
  format: azure/{model_id}
  api_key: default_azure_key_replace_me
  description: Azure OpenAI models

bedrock:
  format: bedrock/{model_id}
  api_key: default_bedrock_key_replace_me
  description: AWS Bedrock models

cohere:
  format: cohere/{model_id}
  api_key: default_cohere_key_replace_me
  description: Cohere models

google:
  format: gemini/{model_id}  # Important! Unlike other providers, Google uses gemini/{model_id}
  api_key: default_google_key_replace_me
  description: Google AI models including Gemini

openai:
  format: {model_id}  # OpenAI uses just the model_id without prefix
  api_key: default_openai_key_replace_me
  description: OpenAI models including GPT-4 and DALL-E